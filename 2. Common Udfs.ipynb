{"cells":[{"cell_type":"markdown","source":["\n","#### Run the cell below to install the required packages for Copilot\n"],"metadata":{"jupyter":{"magics_cell_name":"magics-cell-markdown","magics_signature":"27ac753c3c60167f65c4d05fa7809cd85f1f0273d5b842aca4f65a01"},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f15bbd8d-6886-4c92-a9aa-c3746e8b0f27"},{"cell_type":"code","source":["from faker import Faker\n","fake = Faker()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7924dbc2-6dc0-4a2e-a16f-3756dc797bf5"},{"cell_type":"code","source":["# Function to load data based on file_format\n","def load_data(config_name, location, file_format):\n","    if file_format == \"delta\":\n","        print(f\"Loading Delta data from {location}\")\n","        return spark.read.format(\"delta\").load(location)\n","    elif file_format == \"csv\":\n","        print(f\"Loading CSV data from {location}\")\n","        return spark.read.option(\"header\", \"true\").csv(location)\n","    elif file_format == \"parquet\":\n","        print(f\"Loading Parquet data from {location}\")\n","        return spark.read.parquet(location)\n","    elif file_format == \"table\":\n","        print(f\"Loading table data from {location}\")\n","        return spark.read.load(location)\n","    else:\n","        print(f\"Unsupported file format {file_format} for {config_name}\")\n","        return None"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"be1e0697-6e54-4c8a-8c83-d2fead8cbebc"},{"cell_type":"code","source":["\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import StringType\n","\n","\n","\n","# Define functions\n","def get_fake_first_name(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.first_name()\n","\n","def get_fake_last_name(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.last_name()\n","\n","def get_fake_email(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.email()\n","\n","def get_fake_phone_number(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.phone_number()\n","\n","def get_fake_address(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.address()\n","\n","def get_fake_ssn(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.ssn()\n","\n","def get_fake_passport_number(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.passport_number()\n","\n","def get_fake_street_address(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.street_address()\n","\n","def get_fake_name(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.name()\n","\n","def get_fake_user_name(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.user_name()\n","\n","def get_fake_postalcode(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.postcode()\n","\n","def get_fake_zipcode(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.zipcode()\n","\n","def get_fake_country_code(seedValue):\n","    fake.seed_instance(seedValue)\n","    return fake.country_code()\n","\n","def get_fake_date_of_birth(seedValue):\n","    fake.seed_instance(seedValue)\n","    birth_date = fake.date_of_birth(minimum_age=18, maximum_age=90)\n","    return birth_date.strftime('%Y-%m-%d')\n","\n","# Step 3: Create PySpark UDFs\n","get_fake_first_name_udf = udf(get_fake_first_name, StringType())\n","get_fake_last_name_udf = udf(get_fake_last_name, StringType())\n","get_fake_email_udf = udf(get_fake_email, StringType())\n","get_fake_phone_number_udf = udf(get_fake_phone_number, StringType())\n","get_fake_address_udf = udf(get_fake_address, StringType())\n","get_fake_ssn_udf = udf(get_fake_ssn, StringType())\n","get_fake_passport_number_udf = udf(get_fake_passport_number, StringType())\n","get_fake_street_address_udf = udf(get_fake_street_address, StringType())\n","get_fake_name_udf = udf(get_fake_name, StringType())\n","get_fake_user_name_udf = udf(get_fake_user_name, StringType())\n","get_fake_postalcode_udf = udf(get_fake_postalcode, StringType())\n","get_fake_zipcode_udf = udf(get_fake_zipcode, StringType())\n","get_fake_country_code_udf = udf(get_fake_country_code, StringType())\n","get_fake_date_of_birth_udf = udf(get_fake_date_of_birth, StringType())\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0b58be5b-0b15-4bed-9a27-b746d04c5715"},{"cell_type":"code","source":["def get_fake_df(original_df, pii_column_mapping_config):\n","\n","    if not pii_column_mapping_config:\n","        return original_df\n","    \n","    column_mapping = pii_column_mapping_config #dict(item.split(\": \") for item in column_mapping_config)\n","    print(column_mapping)\n","\n","    for column, fake_type in column_mapping.items():\n","        if fake_type == 'first_name':\n","            original_df = original_df.withColumn(column, get_fake_first_name_udf(original_df[column]))\n","        elif fake_type == 'last_name':\n","            original_df = original_df.withColumn(column, get_fake_last_name_udf(original_df[column]))\n","        elif fake_type == 'email':\n","            original_df = original_df.withColumn(column, get_fake_email_udf(original_df[column]))\n","        elif fake_type == 'phone_number':\n","            original_df = original_df.withColumn(column, get_fake_phone_number_udf(original_df[column]))\n","        elif fake_type == 'address':\n","            original_df = original_df.withColumn(column, get_fake_address_udf(original_df[column]))\n","        elif fake_type == 'ssn':\n","            original_df = original_df.withColumn(column, get_fake_ssn_udf(original_df[column]))\n","        elif fake_type == 'passport_number':\n","            original_df = original_df.withColumn(column, get_fake_passport_number_udf(original_df[column]))\n","        elif fake_type == 'street_address':\n","            original_df = original_df.withColumn(column, get_fake_street_address_udf(original_df[column]))\n","        elif fake_type == 'name':\n","            original_df = original_df.withColumn(column, get_fake_name_udf(original_df[column]))\n","        elif fake_type == 'user_name':\n","            original_df = original_df.withColumn(column, get_fake_user_name_udf(original_df[column]))\n","        elif fake_type == 'postalcode':\n","            original_df = original_df.withColumn(column, get_fake_postalcode_udf(original_df[column]))\n","        elif fake_type == 'zipcode':\n","            original_df = original_df.withColumn(column, get_fake_zipcode_udf(original_df[column]))\n","        elif fake_type == 'country_code':\n","            original_df = original_df.withColumn(column, get_fake_country_code_udf(original_df[column]))\n","        elif fake_type == 'date_of_birth':\n","            original_df = original_df.withColumn(column, get_fake_date_of_birth_udf(original_df[column]))\n","\n","    # Show the updated DataFrame with fake values\n","    return original_df\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e5872e36-cdb8-45aa-9135-3c740fb832f2"},{"cell_type":"code","source":["def save_as_delta(df, config_name):\n","    \"\"\"\n","    Saves the given DataFrame as a Delta table at the specified location.\n","    \n","    :param df: The DataFrame to save.\n","    :param df_name: The name of the DataFrame (used to create the path).\n","    \"\"\"\n","    # Define the save path using the DataFrame name\n","    save_path = f\"Files/fake_data/{config_name}\"\n","\n","    # Save the DataFrame in Delta format\n","    df.write.saveAsTable(\"fake_\"+config_name)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c92f24ae-932d-492a-a5f3-02df458db496"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"3ab02e53-4f44-49f5-a3ff-8949c0fcad15","default_lakehouse_name":"DemoLHBronze","default_lakehouse_workspace_id":"300b1624-58f6-4e24-8445-45e48983de94","known_lakehouses":[{"id":"3ab02e53-4f44-49f5-a3ff-8949c0fcad15"},{"id":"0000c89b-727b-4984-81e3-a829b857bcfb"}]},"environment":{"environmentId":"65c777f9-3d70-4f0c-8adc-8d642fe60746","workspaceId":"300b1624-58f6-4e24-8445-45e48983de94"}}},"nbformat":4,"nbformat_minor":5}